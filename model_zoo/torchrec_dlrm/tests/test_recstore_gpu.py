import torch
import os
import sys
import unittest
import tempfile
import shutil
from torchrec.sparse.jagged_tensor import KeyedJaggedTensor
from torchrec.sparse.jagged_tensor import KeyedTensor

RECSTORE_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../src'))
if RECSTORE_PATH not in sys.path:
    sys.path.insert(0, RECSTORE_PATH)

from python.pytorch.torchrec.EmbeddingBag import RecStoreEmbeddingBagCollection


class TestRecStoreEmbeddingBagCollectionGPU(unittest.TestCase):
    """æµ‹è¯•RecStoreEmbeddingBagCollectionåœ¨GPUä¸Šçš„å„ç§åŠŸèƒ½"""
    
    @classmethod
    def setUpClass(cls):
        """ç±»çº§åˆ«çš„è®¾ç½®ï¼Œæ£€æŸ¥CUDAå¯ç”¨æ€§"""
        if not torch.cuda.is_available():
            raise unittest.SkipTest("CUDAä¸å¯ç”¨ï¼Œè·³è¿‡GPUæµ‹è¯•")
        
        cls.device = torch.device('cuda:0')
        print(f"ä½¿ç”¨GPUè®¾å¤‡: {cls.device}")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        print(f"å½“å‰GPU: {torch.cuda.get_device_name(0)}")
        
        # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºDEBUGä»¥è·å–æ›´å¤šä¿¡æ¯
        os.environ['RECSTORE_LOG_LEVEL'] = '3'
    
    def setUp(self):
        """æ¯ä¸ªæµ‹è¯•å‰çš„è®¾ç½®"""
        # ç¡®ä¿åœ¨GPUä¸Šè¿è¡Œ
        torch.cuda.empty_cache()
        
        # åŸºç¡€é…ç½®
        self.basic_configs = [
            {
                "name": "test_table",
                "num_embeddings": 100,
                "embedding_dim": 16,
                "feature_names": ["test_feature"]
            }
        ]
        
        # å¤šè¡¨é…ç½®
        self.multi_table_configs = [
            {
                "name": "user_table",
                "num_embeddings": 1000,
                "embedding_dim": 16,
                "feature_names": ["user_id"]
            },
            {
                "name": "item_table", 
                "num_embeddings": 500,
                "embedding_dim": 16,
                "feature_names": ["item_id"]
            },
            {
                "name": "category_table",
                "num_embeddings": 100,
                "embedding_dim": 16,
                "feature_names": ["category_id"]
            }
        ]

    def test_gpu_initialization(self):
        """æµ‹è¯•GPUä¸Šçš„åˆå§‹åŒ–åŠŸèƒ½"""
        print("\n=== æµ‹è¯•GPUåˆå§‹åŒ– ===")
        ebc = RecStoreEmbeddingBagCollection(self.basic_configs)
        
        # éªŒè¯é…ç½®
        configs = ebc.embedding_bag_configs()
        self.assertEqual(len(configs), 1)
        self.assertEqual(configs[0].name, "test_table")
        self.assertEqual(configs[0].num_embeddings, 100)
        self.assertEqual(configs[0].embedding_dim, 16)
        
        # éªŒè¯ç‰¹å¾é”®
        self.assertEqual(ebc.feature_keys, ["test_table"])
        
        print("âœ“ GPUåˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

    def test_gpu_forward_pass(self):
        """æµ‹è¯•GPUä¸Šçš„å‰å‘ä¼ æ’­"""
        print("\n=== æµ‹è¯•GPUå‰å‘ä¼ æ’­ ===")
        ebc = RecStoreEmbeddingBagCollection(self.basic_configs)
        
        # æ„é€ GPUä¸Šçš„è¾“å…¥æ•°æ®
        kjt = KeyedJaggedTensor(
            keys=["test_table"],
            values=torch.tensor([1, 2, 3], dtype=torch.int64, device=self.device),
            lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
        )
        
        # å‰å‘ä¼ æ’­
        result = ebc(kjt)
        
        # éªŒè¯ç»“æœ
        self.assertIsInstance(result, KeyedTensor)
        self.assertEqual(result.keys(), ["test_table"])
        self.assertEqual(result.values().shape, (1, 16))
        self.assertEqual(result.values().device, self.device)
        self.assertEqual(result.length_per_key().tolist(), [1])
        
        print(f"âœ“ GPUå‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: {result.values().shape}")

    def test_gpu_multi_table_forward_pass(self):
        """æµ‹è¯•GPUä¸Šå¤šè¡¨å‰å‘ä¼ æ’­"""
        print("\n=== æµ‹è¯•GPUå¤šè¡¨å‰å‘ä¼ æ’­ ===")
        ebc = RecStoreEmbeddingBagCollection(self.multi_table_configs)
        
        # æ„é€ GPUä¸Šçš„å¤šè¡¨è¾“å…¥æ•°æ®
        kjt = KeyedJaggedTensor(
            keys=["user_table", "item_table", "category_table"],
            values=torch.tensor([1, 2, 3, 4, 5], dtype=torch.int64, device=self.device),
            lengths=torch.tensor([1, 2, 2], dtype=torch.int32, device=self.device)
        )
        
        # å‰å‘ä¼ æ’­
        result = ebc(kjt)
        
        # éªŒè¯ç»“æœ
        self.assertIsInstance(result, KeyedTensor)
        self.assertEqual(result.keys(), ["user_table", "item_table", "category_table"])
        self.assertEqual(result.values().shape, (3, 16))
        self.assertEqual(result.values().device, self.device)
        self.assertEqual(result.length_per_key().tolist(), [1, 1, 1])
        
        print(f"âœ“ GPUå¤šè¡¨å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: {result.values().shape}")

    def test_gpu_gradient_update(self):
        """æµ‹è¯•GPUä¸Šçš„æ¢¯åº¦æ›´æ–°åŠŸèƒ½"""
        print("\n=== æµ‹è¯•GPUæ¢¯åº¦æ›´æ–°åŠŸèƒ½ ===")
        ebc = RecStoreEmbeddingBagCollection(self.basic_configs)
        
        # æ„é€ GPUä¸Šçš„è¾“å…¥æ•°æ®
        kjt = KeyedJaggedTensor(
            keys=["test_table"],
            values=torch.tensor([1, 2, 3], dtype=torch.int64, device=self.device),
            lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
        )
        
        # å‰å‘ä¼ æ’­
        result = ebc(kjt)
        
        # æ„é€ GPUä¸Šçš„æ¢¯åº¦
        grad = torch.randn_like(result.values(), device=self.device)
        
        # åå‘ä¼ æ’­
        result.values().requires_grad_(True)
        result.values().backward(grad)
        
        print("âœ“ GPUæ¢¯åº¦æ›´æ–°æµ‹è¯•é€šè¿‡")

    def test_gpu_multi_table_gradient_update(self):
        """æµ‹è¯•GPUä¸Šå¤šè¡¨æ¢¯åº¦æ›´æ–°"""
        print("\n=== æµ‹è¯•GPUå¤šè¡¨æ¢¯åº¦æ›´æ–° ===")
        ebc = RecStoreEmbeddingBagCollection(self.multi_table_configs)
        
        # æ„é€ GPUä¸Šçš„å¤šè¡¨è¾“å…¥æ•°æ®
        kjt = KeyedJaggedTensor(
            keys=["user_table", "item_table", "category_table"],
            values=torch.tensor([1, 2, 3, 4, 5], dtype=torch.int64, device=self.device),
            lengths=torch.tensor([1, 2, 2], dtype=torch.int32, device=self.device)
        )
        
        # å‰å‘ä¼ æ’­
        result = ebc(kjt)
        
        # æ„é€ GPUä¸Šçš„æ¢¯åº¦
        grad = torch.randn_like(result.values(), device=self.device)
        
        # åå‘ä¼ æ’­
        result.values().requires_grad_(True)
        result.values().backward(grad)
        
        print("âœ“ GPUå¤šè¡¨æ¢¯åº¦æ›´æ–°æµ‹è¯•é€šè¿‡")

    def test_gpu_device_transfer(self):
        """æµ‹è¯•GPUè®¾å¤‡é—´æ•°æ®ä¼ è¾“"""
        print("\n=== æµ‹è¯•GPUè®¾å¤‡é—´æ•°æ®ä¼ è¾“ ===")
        ebc = RecStoreEmbeddingBagCollection(self.basic_configs)
        
        # åœ¨CPUä¸Šæ„é€ æ•°æ®
        cpu_kjt = KeyedJaggedTensor(
            keys=["test_table"],
            values=torch.tensor([1, 2, 3], dtype=torch.int64),
            lengths=torch.tensor([2, 1], dtype=torch.int32)
        )
        
        # è½¬ç§»åˆ°GPU
        gpu_kjt = KeyedJaggedTensor(
            keys=cpu_kjt.keys(),
            values=cpu_kjt.values().to(self.device),
            lengths=cpu_kjt.lengths().to(self.device)
        )
        
        # åœ¨GPUä¸Šå‰å‘ä¼ æ’­
        result = ebc(gpu_kjt)
        
        # éªŒè¯ç»“æœåœ¨GPUä¸Š
        self.assertEqual(result.values().device, self.device)
        
        # è½¬ç§»å›CPU
        cpu_result = result.values().cpu()
        self.assertEqual(cpu_result.device.type, 'cpu')
        
        print("âœ“ GPUè®¾å¤‡é—´æ•°æ®ä¼ è¾“æµ‹è¯•é€šè¿‡")

    def test_gpu_large_batch_forward_pass(self):
        """æµ‹è¯•GPUä¸Šå¤§æ‰¹æ¬¡å‰å‘ä¼ æ’­"""
        print("\n=== æµ‹è¯•GPUå¤§æ‰¹æ¬¡å‰å‘ä¼ æ’­ ===")
        ebc = RecStoreEmbeddingBagCollection(self.basic_configs)
        
        # æ„é€ GPUä¸Šçš„å¤§æ‰¹æ¬¡æ•°æ®
        batch_size = 1000
        ids = torch.randint(0, 100, (batch_size,), dtype=torch.int64, device=self.device)
        lengths = torch.ones(batch_size, dtype=torch.int32, device=self.device)
        
        kjt = KeyedJaggedTensor(
            keys=["test_table"],
            values=ids,
            lengths=lengths
        )
        
        # å‰å‘ä¼ æ’­
        result = ebc(kjt)
        
        # éªŒè¯ç»“æœ
        self.assertEqual(result.values().shape, (1, 16))
        self.assertEqual(result.values().device, self.device)
        
        print("âœ“ GPUå¤§æ‰¹æ¬¡å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")

    def test_gpu_memory_management(self):
        """æµ‹è¯•GPUå†…å­˜ç®¡ç†"""
        print("\n=== æµ‹è¯•GPUå†…å­˜ç®¡ç† ===")
        ebc = RecStoreEmbeddingBagCollection(self.basic_configs)
        
        # è®°å½•åˆå§‹å†…å­˜ä½¿ç”¨
        initial_memory = torch.cuda.memory_allocated()
        
        # è¿›è¡Œå¤šæ¬¡å‰å‘ä¼ æ’­
        for i in range(10):
            kjt = KeyedJaggedTensor(
                keys=["test_table"],
                values=torch.tensor([i, i+1, i+2], dtype=torch.int64, device=self.device),
                lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
            )
            result = ebc(kjt)
            
            # ç¡®ä¿ç»“æœåœ¨GPUä¸Š
            self.assertEqual(result.values().device, self.device)
        
        # æ¸…ç†å†…å­˜
        torch.cuda.empty_cache()
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨æ˜¯å¦åˆç†
        final_memory = torch.cuda.memory_allocated()
        memory_increase = final_memory - initial_memory
        
        print(f"å†…å­˜ä½¿ç”¨å¢åŠ : {memory_increase / 1024 / 1024:.2f} MB")
        
        print("âœ“ GPUå†…å­˜ç®¡ç†æµ‹è¯•é€šè¿‡")

    def test_gpu_mixed_precision(self):
        """æµ‹è¯•GPUæ··åˆç²¾åº¦"""
        print("\n=== æµ‹è¯•GPUæ··åˆç²¾åº¦ ===")
        ebc = RecStoreEmbeddingBagCollection(self.basic_configs)
        
        # ä½¿ç”¨åŠç²¾åº¦
        with torch.cuda.amp.autocast():
            kjt = KeyedJaggedTensor(
                keys=["test_table"],
                values=torch.tensor([1, 2, 3], dtype=torch.int64, device=self.device),
                lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
            )
            
            result = ebc(kjt)
            
            # éªŒè¯ç»“æœ
            self.assertEqual(result.values().device, self.device)
            # æ³¨æ„ï¼šåœ¨æ··åˆç²¾åº¦ä¸‹ï¼Œè¾“å‡ºå¯èƒ½æ˜¯float16æˆ–float32
            self.assertIn(result.values().dtype, [torch.float16, torch.float32])
        
        print("âœ“ GPUæ··åˆç²¾åº¦æµ‹è¯•é€šè¿‡")

    def test_gpu_concurrent_operations(self):
        """æµ‹è¯•GPUå¹¶å‘æ“ä½œ"""
        print("\n=== æµ‹è¯•GPUå¹¶å‘æ“ä½œ ===")
        ebc = RecStoreEmbeddingBagCollection(self.basic_configs)
        
        # åˆ›å»ºå¤šä¸ªæµ
        streams = [torch.cuda.Stream() for _ in range(3)]
        
        results = []
        for i, stream in enumerate(streams):
            with torch.cuda.stream(stream):
                kjt = KeyedJaggedTensor(
                    keys=["test_table"],
                    values=torch.tensor([i, i+1, i+2], dtype=torch.int64, device=self.device),
                    lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
                )
                result = ebc(kjt)
                results.append(result)
        
        # åŒæ­¥æ‰€æœ‰æµ
        torch.cuda.synchronize()
        
        # éªŒè¯æ‰€æœ‰ç»“æœ
        for i, result in enumerate(results):
            self.assertEqual(result.values().device, self.device)
            self.assertEqual(result.values().shape, (1, 16))
        
        print("âœ“ GPUå¹¶å‘æ“ä½œæµ‹è¯•é€šè¿‡")

    def test_gpu_error_handling(self):
        """æµ‹è¯•GPUé”™è¯¯å¤„ç†"""
        print("\n=== æµ‹è¯•GPUé”™è¯¯å¤„ç† ===")
        ebc = RecStoreEmbeddingBagCollection(self.basic_configs)
        
        # æµ‹è¯•ä¸å­˜åœ¨çš„è¡¨
        with self.assertRaises(RuntimeError):
            ebc.kv_client.pull("non_existent_table", torch.tensor([1], device=self.device))
        
        # æµ‹è¯•æ— æ•ˆçš„IDèŒƒå›´
        kjt = KeyedJaggedTensor(
            keys=["test_table"],
            values=torch.tensor([999], dtype=torch.int64, device=self.device),  # è¶…å‡ºèŒƒå›´çš„ID
            lengths=torch.tensor([1], dtype=torch.int32, device=self.device)
        )
        
        # è¿™åº”è¯¥ä¸ä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œè€Œæ˜¯è¿”å›é›¶å‘é‡
        result = ebc(kjt)
        self.assertEqual(result.values().shape, (1, 16))
        self.assertEqual(result.values().device, self.device)
        
        print("âœ“ GPUé”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")

    def test_gpu_performance_benchmark(self):
        """æµ‹è¯•GPUæ€§èƒ½åŸºå‡†"""
        print("\n=== æµ‹è¯•GPUæ€§èƒ½åŸºå‡† ===")
        ebc = RecStoreEmbeddingBagCollection(self.basic_configs)
        
        # é¢„çƒ­
        for _ in range(5):
            kjt = KeyedJaggedTensor(
                keys=["test_table"],
                values=torch.tensor([1, 2, 3], dtype=torch.int64, device=self.device),
                lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
            )
            _ = ebc(kjt)
        
        torch.cuda.synchronize()
        
        # æ€§èƒ½æµ‹è¯•
        batch_size = 100
        num_iterations = 100
        
        start_event = torch.cuda.Event(enable_timing=True)
        end_event = torch.cuda.Event(enable_timing=True)
        
        start_event.record()
        
        for _ in range(num_iterations):
            kjt = KeyedJaggedTensor(
                keys=["test_table"],
                values=torch.randint(0, 100, (batch_size,), dtype=torch.int64, device=self.device),
                lengths=torch.ones(batch_size, dtype=torch.int32, device=self.device)
            )
            result = ebc(kjt)
        
        end_event.record()
        torch.cuda.synchronize()
        
        elapsed_time = start_event.elapsed_time(end_event)
        throughput = num_iterations / (elapsed_time / 1000)  # iterations per second
        
        print(f"GPUæ€§èƒ½åŸºå‡†: {elapsed_time:.2f}ms for {num_iterations} iterations")
        print(f"ååé‡: {throughput:.2f} iterations/second")
        
        print("âœ“ GPUæ€§èƒ½åŸºå‡†æµ‹è¯•é€šè¿‡")

    def test_gpu_multi_device(self):
        """æµ‹è¯•å¤šGPUè®¾å¤‡"""
        print("\n=== æµ‹è¯•å¤šGPUè®¾å¤‡ ===")
        if torch.cuda.device_count() < 2:
            self.skipTest("éœ€è¦è‡³å°‘2ä¸ªGPUè®¾å¤‡")
        
        ebc = RecStoreEmbeddingBagCollection(self.basic_configs)
        
        # æµ‹è¯•åœ¨ä¸åŒGPUä¸Šè¿è¡Œ
        for device_id in range(min(2, torch.cuda.device_count())):
            device = torch.device(f'cuda:{device_id}')
            
            with torch.cuda.device(device):
                kjt = KeyedJaggedTensor(
                    keys=["test_table"],
                    values=torch.tensor([1, 2, 3], dtype=torch.int64, device=device),
                    lengths=torch.tensor([2, 1], dtype=torch.int32, device=device)
                )
                
                result = ebc(kjt)
                
                # éªŒè¯ç»“æœåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
                self.assertEqual(result.values().device, device)
        
        print("âœ“ å¤šGPUè®¾å¤‡æµ‹è¯•é€šè¿‡")

    def test_gpu_tensor_operations(self):
        """æµ‹è¯•GPUå¼ é‡æ“ä½œ"""
        print("\n=== æµ‹è¯•GPUå¼ é‡æ“ä½œ ===")
        ebc = RecStoreEmbeddingBagCollection(self.basic_configs)
        
        # æµ‹è¯•ä¸åŒçš„å¼ é‡æ“ä½œ
        kjt = KeyedJaggedTensor(
            keys=["test_table"],
            values=torch.tensor([1, 2, 3], dtype=torch.int64, device=self.device),
            lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
        )
        
        result = ebc(kjt)
        
        # æµ‹è¯•å¼ é‡æ“ä½œ
        result_squared = result.values() ** 2
        result_sum = result.values().sum()
        result_mean = result.values().mean()
        
        # éªŒè¯æ“ä½œç»“æœ
        self.assertEqual(result_squared.device, self.device)
        self.assertEqual(result_sum.device, self.device)
        self.assertEqual(result_mean.device, self.device)
        
        print("âœ“ GPUå¼ é‡æ“ä½œæµ‹è¯•é€šè¿‡")

    def test_gpu_gradient_accumulation(self):
        """æµ‹è¯•GPUæ¢¯åº¦ç´¯ç§¯"""
        print("\n=== æµ‹è¯•GPUæ¢¯åº¦ç´¯ç§¯ ===")
        ebc = RecStoreEmbeddingBagCollection(self.basic_configs)
        
        # å¤šæ¬¡å‰å‘ä¼ æ’­å’Œæ¢¯åº¦ç´¯ç§¯
        accumulated_grad = None
        
        for i in range(3):
            kjt = KeyedJaggedTensor(
                keys=["test_table"],
                values=torch.tensor([i, i+1, i+2], dtype=torch.int64, device=self.device),
                lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
            )
            
            result = ebc(kjt)
            result.values().requires_grad_(True)
            
            # è®¡ç®—æŸå¤±
            loss = result.values().sum()
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # ç´¯ç§¯æ¢¯åº¦
            if accumulated_grad is None:
                accumulated_grad = result.values().grad.clone()
            else:
                accumulated_grad += result.values().grad
        
        # éªŒè¯æ¢¯åº¦ç´¯ç§¯
        self.assertIsNotNone(accumulated_grad)
        self.assertEqual(accumulated_grad.device, self.device)
        
        print("âœ“ GPUæ¢¯åº¦ç´¯ç§¯æµ‹è¯•é€šè¿‡")


def run_all_gpu_tests():
    """è¿è¡Œæ‰€æœ‰GPUæµ‹è¯•"""
    print("å¼€å§‹è¿è¡ŒRecStoreEmbeddingBagCollection GPUæµ‹è¯•å¥—ä»¶...")
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œæ— æ³•è¿è¡ŒGPUæµ‹è¯•")
        return False
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestRecStoreEmbeddingBagCollectionGPU)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # æ‰“å°æ€»ç»“
    print(f"\nGPUæµ‹è¯•æ€»ç»“:")
    print(f"è¿è¡Œæµ‹è¯•æ•°: {result.testsRun}")
    print(f"å¤±è´¥æµ‹è¯•æ•°: {len(result.failures)}")
    print(f"é”™è¯¯æµ‹è¯•æ•°: {len(result.errors)}")
    print(f"è·³è¿‡æµ‹è¯•æ•°: {len(result.skipped)}")
    
    if result.failures:
        print("\nå¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"- {test}: {traceback}")
    
    if result.errors:
        print("\né”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"- {test}: {traceback}")
    
    if result.skipped:
        print("\nè·³è¿‡çš„æµ‹è¯•:")
        for test, reason in result.skipped:
            print(f"- {test}: {reason}")
    
    return result.wasSuccessful()


def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡Œæ‰€æœ‰GPUæµ‹è¯•"""
    success = run_all_gpu_tests()
    if success:
        print("\nğŸ‰ æ‰€æœ‰GPUæµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâŒ éƒ¨åˆ†GPUæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")
    return success


if __name__ == "__main__":
    main()